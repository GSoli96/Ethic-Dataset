# LLM-enhanced PGD
...
# Ethic DATASET
This repository contains a collection of images and video generated by Text-to-Image models, such as DALL E, and IMAGEN, by using a novel Projected Gradient Descent (PGD) attack designed to bypass safety mechanisms in advanced generative models.

The data is for non-commercial research purposes only. 
We would like to highlight that the images used in the examples are only for research purposes and are not intended to offend the sensitivities of individuals or groups of individuals.

## Data Organization

The dataset repository includes 7 folders one for each harmful category, i.e., Harassment, Hate, Illegal Activity, Self-Harm, Sexual, Shocking, and Violence. 

## Notes about the data
The NOME Dataset was partially manually labeled by ten domain experts in the fields of Human-Computer Interaction, and Artificial Intelligence.    

...
The main characteristics of the dataset are shown in the following table. 

|    Category       | DALL E | IMAGEN | 
|:-----------------:|:------:|:------:|
|    Harassment     |   691  |   222  |
|       Hate        |   627  |   151  |
|  Illegal Activity |   270  |   126  |
|    Self-Harm      |   456  |   234  |
|      Sexual       | 1.315  |   563  |
|     Shocking      |   671  |   359  |
|     Violence      |   471  |   181  |
|      **Total**        | 4.501  | 1.836  |


## Data Usage Agreement/ How to cite

By using this dataset, you agree to cite the following article: 

```
@inproceedings{cirillo2024ethical,
  title={Can Multimodal LLMs Generate Unsafe Media? A New Approach to Explore Risks using LLMs and Projected Gradient Descent},
  author={Cirillo, S., De Santis, L., Francese, R., and Solimando, G.},
  booktitle={TBD},
  year={2024}
}
```
